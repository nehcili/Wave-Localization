{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density of State Neural Net (DOSNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# I/O \n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regime: 200 1000 20\n"
     ]
    }
   ],
   "source": [
    "# set in data_gen\n",
    "TEST = False\n",
    "\n",
    "# in this doc\n",
    "if TEST:\n",
    "    BATCH_SIZE = 7\n",
    "    EPOCHS = 40\n",
    "    PATH='test_data/'\n",
    "    FILE_NAME = 't'\n",
    "else:\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 40\n",
    "    PATH='data/'\n",
    "    FILE_NAME = 'toy'\n",
    "\n",
    "# other relavant parameters\n",
    "with open(PATH+FILE_NAME+'_params.txt') as f:\n",
    "    f.readline()\n",
    "    BOXLENGTH, DATA_SIZE, NEV = list(map(int, f.readline().split(','))) \n",
    "NAMES = ['dos', 'evs', 'landScapePotential', 'originalPotentialPotential']\n",
    "\n",
    "print(\"Regime:\", BOXLENGTH, DATA_SIZE, NEV)\n",
    "#EPSILON = np.finfo(np.float32).tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(names=NAMES, path=PATH, file_name=FILE_NAME):        \n",
    "    train, test= [], []\n",
    "    for i in range(len(names)):\n",
    "        train.append(loadtxt(path + file_name + '_train_' + names[i] + '.cvs', delimiter=',').astype(np.float32))\n",
    "        test.append(loadtxt(path + file_name + '_test_' + names[i] + '.cvs', delimiter=',').astype(np.float32))\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# form data for training/testing\n",
    "# NOTE: cannot set data_size=DATA_SIZE as DATA_SIZE = 0 before loading\n",
    "def form_data(train, test, data_size=DATA_SIZE, batch_size=BATCH_SIZE): \n",
    "    train_ds, test_ds = [], []\n",
    "    for i in range(len(train)-2):\n",
    "        train[i+2] = train[i+2][..., tf.newaxis]\n",
    "        test[i+2] = test[i+2][..., tf.newaxis]\n",
    "        train_ds.append(tf.data.Dataset.from_tensor_slices( \\\n",
    "            (train[i+2], train[1][..., tf.newaxis, tf.newaxis], train[0])).shuffle(data_size).batch(batch_size))\n",
    "        test_ds.append(tf.data.Dataset.from_tensor_slices( \\\n",
    "            (test[i+2], test[1][..., tf.newaxis, tf.newaxis], test[0])).batch(batch_size))\n",
    "    \n",
    "    return train_ds, test_ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    train_test_data, test_test_data = load()\n",
    "    print('BOXLENGTH, DATA_SIZE, NEV:')\n",
    "    print(BOXLENGTH, DATA_SIZE, NEV)\n",
    "    train_ds, test_ds = form_data(train_test_data, test_test_data) \n",
    "    print(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Box Counting Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The original (nontrainable) box counting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x has input size: boxlength x channels\n",
    "# output shape:     (3*channels)\n",
    "def boxCount(x, box_size):\n",
    "    x1 = tf.nn.avg_pool(x, box_size, box_size, 'SAME')\n",
    "    x1 = tf.nn.relu(x1)\n",
    "    x1 = tf.math.sign(x1)\n",
    "    x1 = tf.reduce_sum(x1, axis=1)\n",
    "    \n",
    "    x2 = tf.nn.max_pool(x, box_size, box_size, 'SAME')\n",
    "    x2 = tf.nn.relu(x2)\n",
    "    x2 = tf.math.sign(x2)\n",
    "    x2 = tf.reduce_sum(x2, axis=1)\n",
    "    \n",
    "    x3 = -tf.nn.max_pool(-x, box_size, box_size, 'SAME')\n",
    "    x3 = tf.nn.relu(x3)\n",
    "    x3 = tf.math.sign(x3)\n",
    "    x3 = tf.reduce_sum(x3, axis=1)\n",
    "    \n",
    "    return tf.concat([x1,x2,x3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN to train for weights (and compute weighted sum different box countings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toyBC(Model):\n",
    "    def __init__(self, n, boxlength=BOXLENGTH, potential_type=\"\"):\n",
    "        super(toyBC, self).__init__(name='')\n",
    "        \n",
    "        self.potential_type=potential_type\n",
    "        self.n = n\n",
    "        self.D = [int(1.6**i) for i in range(self.n)]\n",
    "        \n",
    "        #strides = int(np.cbrt(boxlength/3/(2*n+1)))+1\n",
    "        #self.conv1 = layers.Conv1D(n, \n",
    "        #                           kernel_size=2*stride,\n",
    "        #                           strides=strides, \n",
    "        #                           padding='same')\n",
    "        #self.norm1 = layers.BatchNormalization()\n",
    "        #self.activation1 = tf.keras.activations.softplus()\n",
    "        \n",
    "        self.denses = []\n",
    "        self.activs = []\n",
    "        self.denses.append(layers.Dense(12*n))\n",
    "        self.activs.append(layers.PReLU())\n",
    "        self.denses.append(layers.Dense(6*n))\n",
    "        self.activs.append(layers.PReLU())\n",
    "        self.denses.append(layers.Dense(3*n)) \n",
    "        self.activs.append(layers.PReLU())\n",
    "        #self.norms = [layers.BatchNormalization() for i in range(len(self.denses)-1)]\n",
    "        self.boxlength=boxlength\n",
    "        \n",
    "            \n",
    "    \n",
    "    def call(self, x, E):\n",
    "        y = tf.concat([boxCount(x-E, d) for d in self.D], axis=1)  \n",
    "        \n",
    "        E=E-x\n",
    "        if E.shape[0] != 1:\n",
    "            E = tf.squeeze(E)\n",
    "        else:\n",
    "            E = E[0]\n",
    "        for i in range(len(self.denses)):\n",
    "            E = self.denses[i](E)\n",
    "            E = self.activs[i](E)\n",
    "        #E = self.denses[-1](E)\n",
    "        \n",
    "        if E.shape[0] != 1:\n",
    "            E = tf.squeeze(E)\n",
    "        else:\n",
    "            E = E[0]\n",
    "        \n",
    "        return tf.reduce_sum(tf.multiply(y, E), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    x = train_test_data[2]\n",
    "    evs = train_test_data[1][..., np.newaxis, np.newaxis]\n",
    "    print(\"x.shape:\", x.shape)\n",
    "    print(\"evs.shape:\", evs.shape)\n",
    "    bxC = toyBC(4)\n",
    "    print(\"output:\", bxC(x, evs).shape)\n",
    "    print(bxC.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_ds=None, test_ds=None, epochs=EPOCHS):\n",
    "    loss_object = tf.keras.losses.MeanSquaredError() #MeanAbsoluteError() #   #MeanAbsolutePercentageError()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(x, ev, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x, ev)\n",
    "            loss = loss_object(target, predictions)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            train_loss(loss)\n",
    "            \n",
    "            \n",
    "    @tf.function\n",
    "    def test_step(x, ev, target):\n",
    "        predictions = model(x, ev)\n",
    "        #print(predictions.shape, target.shape)\n",
    "        t_loss = loss_object(target, predictions)\n",
    "\n",
    "        test_loss(t_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        test_loss.reset_states()\n",
    "\n",
    "        for x, ev, target in train_ds:\n",
    "            train_step(x, ev, target)\n",
    "\n",
    "        for x, ev, target in test_ds:\n",
    "            test_step(x, ev, target)\n",
    "\n",
    "        template = 'Epoch {}, Training Loss: {}, Test Loss: {}'\n",
    "        print(template.format(epoch+1,\n",
    "                            train_loss.result(),\n",
    "                            test_loss.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(train_ds, test_ds, sample, epochs=EPOCHS, nev=NEV, boxlength=BOXLENGTH):\n",
    "    \n",
    "    # defining models\n",
    "    models = []\n",
    "    models.append(toyBC(9,\n",
    "                           boxlength=boxlength, \n",
    "                           potential_type='1/u based'))\n",
    "    models.append(toyBC(9,\n",
    "                           boxlength=boxlength, \n",
    "                           potential_type='V based'))\n",
    "    #models.append(DOSNN(input_channel=2, potential_type='uV based'))\n",
    "    \n",
    "    # training\n",
    "    for i, model in enumerate(models):\n",
    "        print(\"-------------------------------------------\")\n",
    "        print(\"| Starting training for {} model\".format(model.potential_type))\n",
    "        print(\"-------------------------------------------\")\n",
    "        \n",
    "        train(model, train_ds=train_ds[i], test_ds=test_ds[i], epochs=epochs)\n",
    "        print(\"\")\n",
    "        print(model.summary())\n",
    "        print(\"\")\n",
    "    print(\"Training finished\\n\")\n",
    "    \n",
    "    \n",
    "    # displaying some numerical values\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"| Displaying numerical values for comparison\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"True DOS:\")\n",
    "    print(sample[0][:nev])\n",
    "    print(sample[1][:nev])\n",
    "    #print(sample)\n",
    "    \n",
    "    pred = []\n",
    "    for i in range(len(models)):\n",
    "        pred.append(models[i](sample[i+2][:nev], sample[1][:nev][..., np.newaxis, np.newaxis]))\n",
    "        print(\"\")\n",
    "        print(\"Results from {} GSNN\".format(models[i].potential_type))\n",
    "        print(pred[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = form_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| Starting training for 1/u based model\n",
      "-------------------------------------------\n",
      "Epoch 1, Training Loss: 55.114681243896484, Test Loss: 3.229755401611328\n",
      "Epoch 2, Training Loss: 24.955718994140625, Test Loss: 2.609142780303955\n",
      "Epoch 3, Training Loss: 12.468770980834961, Test Loss: 2.3858160972595215\n",
      "Epoch 4, Training Loss: 110.12738800048828, Test Loss: 2.408450126647949\n",
      "Epoch 5, Training Loss: 15.667160987854004, Test Loss: 2.1343142986297607\n",
      "Epoch 6, Training Loss: 1.8552820682525635, Test Loss: 1.9168909788131714\n",
      "Epoch 7, Training Loss: 2.053762912750244, Test Loss: 1.8986568450927734\n",
      "Epoch 8, Training Loss: 25.5871524810791, Test Loss: 1.8044668436050415\n",
      "Epoch 9, Training Loss: 1.837149977684021, Test Loss: 1.8196332454681396\n",
      "Epoch 10, Training Loss: 3.1686251163482666, Test Loss: 1.8117727041244507\n",
      "Epoch 11, Training Loss: 1.2405744791030884, Test Loss: 1.7530819177627563\n",
      "Epoch 12, Training Loss: 1.571907877922058, Test Loss: 1.8349378108978271\n",
      "Epoch 13, Training Loss: 2.4022953510284424, Test Loss: 1.7977112531661987\n",
      "Epoch 14, Training Loss: 16.88332176208496, Test Loss: 1.795464038848877\n",
      "Epoch 15, Training Loss: 19.732637405395508, Test Loss: 1.8858121633529663\n",
      "Epoch 16, Training Loss: 4.0180253982543945, Test Loss: 1.787078619003296\n",
      "Epoch 17, Training Loss: 1.2061856985092163, Test Loss: 1.7629187107086182\n",
      "Epoch 18, Training Loss: 1.3692820072174072, Test Loss: 1.7388155460357666\n",
      "Epoch 19, Training Loss: 0.8907971382141113, Test Loss: 1.705306053161621\n",
      "Epoch 20, Training Loss: 1.2331815958023071, Test Loss: 1.7210482358932495\n",
      "Epoch 21, Training Loss: 6.29095983505249, Test Loss: 1.8223732709884644\n",
      "Epoch 22, Training Loss: 4.448413372039795, Test Loss: 1.8376983404159546\n",
      "Epoch 23, Training Loss: 0.9841970801353455, Test Loss: 1.7481290102005005\n",
      "Epoch 24, Training Loss: 1.4022352695465088, Test Loss: 1.868690848350525\n",
      "Epoch 25, Training Loss: 0.8703271746635437, Test Loss: 1.8173613548278809\n",
      "Epoch 26, Training Loss: 0.8795030117034912, Test Loss: 1.8711981773376465\n",
      "Epoch 27, Training Loss: 0.7272613644599915, Test Loss: 1.8373034000396729\n",
      "Epoch 28, Training Loss: 1.520546555519104, Test Loss: 1.790030598640442\n",
      "Epoch 29, Training Loss: 0.7956922650337219, Test Loss: 1.926276683807373\n",
      "Epoch 30, Training Loss: 5.516425609588623, Test Loss: 1.8105220794677734\n",
      "Epoch 31, Training Loss: 11.783797264099121, Test Loss: 2.080486297607422\n",
      "Epoch 32, Training Loss: 3.9569921493530273, Test Loss: 1.8242913484573364\n",
      "Epoch 33, Training Loss: 0.8562386631965637, Test Loss: 1.8155590295791626\n",
      "Epoch 34, Training Loss: 0.7416643500328064, Test Loss: 1.8277136087417603\n",
      "Epoch 35, Training Loss: 0.8306810259819031, Test Loss: 1.873099446296692\n",
      "Epoch 36, Training Loss: 0.8859071135520935, Test Loss: 1.8574174642562866\n",
      "Epoch 37, Training Loss: 7.366106986999512, Test Loss: 1.9972586631774902\n",
      "Epoch 38, Training Loss: 2.2013750076293945, Test Loss: 1.9520373344421387\n",
      "Epoch 39, Training Loss: 21.136878967285156, Test Loss: 2.214571237564087\n",
      "Epoch 40, Training Loss: 7.481306076049805, Test Loss: 1.9787408113479614\n",
      "\n",
      "Model: \"toy_bc\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  21708     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  5886      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1485      \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              multiple                  108       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            multiple                  54        \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            multiple                  27        \n",
      "=================================================================\n",
      "Total params: 29,268\n",
      "Trainable params: 29,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "-------------------------------------------\n",
      "| Starting training for V based model\n",
      "-------------------------------------------\n",
      "Epoch 1, Training Loss: 23.42985725402832, Test Loss: 7.906938076019287\n",
      "Epoch 2, Training Loss: 2.2848074436187744, Test Loss: 5.58991003036499\n",
      "Epoch 3, Training Loss: 1.3258426189422607, Test Loss: 5.319301128387451\n",
      "Epoch 4, Training Loss: 1.1591651439666748, Test Loss: 4.193766117095947\n",
      "Epoch 5, Training Loss: 1.0617953538894653, Test Loss: 3.709012985229492\n",
      "Epoch 6, Training Loss: 1.0368698835372925, Test Loss: 2.790724039077759\n",
      "Epoch 7, Training Loss: 0.929526150226593, Test Loss: 2.527641534805298\n",
      "Epoch 8, Training Loss: 0.932090699672699, Test Loss: 2.283470392227173\n",
      "Epoch 9, Training Loss: 0.8926287889480591, Test Loss: 2.042268753051758\n",
      "Epoch 10, Training Loss: 0.8029136657714844, Test Loss: 2.0469048023223877\n",
      "Epoch 11, Training Loss: 0.7524663805961609, Test Loss: 1.9416041374206543\n",
      "Epoch 12, Training Loss: 0.8028045296669006, Test Loss: 2.0109171867370605\n",
      "Epoch 13, Training Loss: 0.7302109003067017, Test Loss: 2.0005996227264404\n",
      "Epoch 14, Training Loss: 0.6833662986755371, Test Loss: 2.049309015274048\n",
      "Epoch 15, Training Loss: 0.6484816670417786, Test Loss: 2.2109296321868896\n",
      "Epoch 16, Training Loss: 0.6275313496589661, Test Loss: 1.9337434768676758\n",
      "Epoch 17, Training Loss: 0.6319219470024109, Test Loss: 2.089231252670288\n",
      "Epoch 18, Training Loss: 0.5828678607940674, Test Loss: 2.022568464279175\n",
      "Epoch 19, Training Loss: 0.635636031627655, Test Loss: 4.746552467346191\n",
      "Epoch 20, Training Loss: 0.6873475313186646, Test Loss: 1.9784729480743408\n",
      "Epoch 21, Training Loss: 0.5612489581108093, Test Loss: 2.0764377117156982\n",
      "Epoch 22, Training Loss: 0.7212169766426086, Test Loss: 2.2778208255767822\n",
      "Epoch 23, Training Loss: 0.5549232363700867, Test Loss: 2.118852138519287\n",
      "Epoch 24, Training Loss: 0.5090734362602234, Test Loss: 2.0897586345672607\n",
      "Epoch 25, Training Loss: 0.4908044934272766, Test Loss: 2.057279348373413\n",
      "Epoch 26, Training Loss: 0.5020691752433777, Test Loss: 2.3608152866363525\n",
      "Epoch 27, Training Loss: 0.4970046877861023, Test Loss: 2.139871120452881\n",
      "Epoch 28, Training Loss: 0.5025004148483276, Test Loss: 2.2202394008636475\n",
      "Epoch 29, Training Loss: 0.5139074325561523, Test Loss: 2.1275832653045654\n",
      "Epoch 30, Training Loss: 0.49921944737434387, Test Loss: 2.0645058155059814\n",
      "Epoch 31, Training Loss: 0.47380098700523376, Test Loss: 2.0611538887023926\n",
      "Epoch 32, Training Loss: 0.46866485476493835, Test Loss: 2.052612781524658\n",
      "Epoch 33, Training Loss: 0.47930267453193665, Test Loss: 2.144320487976074\n",
      "Epoch 34, Training Loss: 0.47292572259902954, Test Loss: 2.0181236267089844\n",
      "Epoch 35, Training Loss: 0.46680423617362976, Test Loss: 2.14056134223938\n",
      "Epoch 36, Training Loss: 0.4369564950466156, Test Loss: 2.1048145294189453\n",
      "Epoch 37, Training Loss: 0.44121357798576355, Test Loss: 2.0968010425567627\n",
      "Epoch 38, Training Loss: 0.440470814704895, Test Loss: 2.0959815979003906\n",
      "Epoch 39, Training Loss: 0.45826172828674316, Test Loss: 2.2041871547698975\n",
      "Epoch 40, Training Loss: 0.4327377378940582, Test Loss: 2.0640664100646973\n",
      "\n",
      "Model: \"toy_bc_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              multiple                  21708     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  5886      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  1485      \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            multiple                  108       \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            multiple                  54        \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            multiple                  27        \n",
      "=================================================================\n",
      "Total params: 29,268\n",
      "Trainable params: 29,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Training finished\n",
      "\n",
      "-------------------------------------------\n",
      "| Displaying numerical values for comparison\n",
      "-------------------------------------------\n",
      "True DOS:\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.\n",
      " 19. 20.]\n",
      "[0.12904008 0.24016875 0.31700215 0.32079244 0.32967708 0.37422836\n",
      " 0.38722613 0.3926253  0.39564905 0.40305397 0.4037546  0.42885053\n",
      " 0.42926615 0.45099196 0.45817822 0.4800069  0.48413718 0.5037589\n",
      " 0.5196402  0.532502  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results from 1/u based GSNN\n",
      "tf.Tensor(\n",
      "[ 0.18828297  2.2519999   5.218706    5.4095297   5.9711194   8.812729\n",
      "  9.63295    10.141993   10.332783   10.575373   10.645163   12.427897\n",
      " 12.486566   14.658957   14.935569   16.867205   17.345348   17.43969\n",
      " 18.749802   19.496418  ], shape=(20,), dtype=float32)\n",
      "\n",
      "Results from V based GSNN\n",
      "tf.Tensor(\n",
      "[ 0.6010256  1.309247   3.4265718  3.5883055  4.2400727  6.891802\n",
      "  8.024151   8.382543   8.677709   9.386555   9.456062  12.02324\n",
      " 12.048126  13.51689   13.980864  16.120968  16.316586  17.524872\n",
      " 18.562906  19.614555 ], shape=(20,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "compare_models(train_ds, test_ds, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
