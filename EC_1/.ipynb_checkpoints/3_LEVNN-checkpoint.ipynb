{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landscape Ground State Landscape Neural Net\n",
    "## 1. Goal\n",
    "The goal of this project is to show case the effectiveness of the landscape function by comparing a simple machine learning architecture (CNN + dense) when trained on\n",
    "1. potential $V$ only, or\n",
    "2. landscape $u$ only, or\n",
    "3. both $u$ and $V$.\n",
    "to predict the lower ground state energy of a Schrodinger's operator. \n",
    "\n",
    "More precisely,\n",
    "- Given a potential $V$ on $L^2(Q_L)$ where $Q_L = [0, L] \\cap \\mathbb{Z}$ with periodic boundary condition\n",
    "- Find the ground state eigenvalue of the disrete Schrodinger Hamiltonian $-\\Delta+V$ where $-\\Delta$ is the discrite Laplacian on $\\mathbb{Z}$.\n",
    "\n",
    "### Architecture\n",
    "- CNN + fully connected NN\n",
    "- implemented by hand as python classes (not using tf.keras.Sequential), to facilitate future upgrades\n",
    "- No optimization such as image augmentation/rotation/translation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# I/O \n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setting Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regime: 1024 5000 20\n"
     ]
    }
   ],
   "source": [
    "# set in data_gen\n",
    "TEST = False\n",
    "\n",
    "# in this doc\n",
    "if TEST:\n",
    "    BATCH_SIZE = 3\n",
    "    EPOCHS = 4\n",
    "    PATH='test_data/'\n",
    "    FILE_NAME = 'td'\n",
    "    PARAMS = [(4, 4,1), (8, 5,4), (16, 5,5)]\n",
    "else:\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 30\n",
    "    PATH='data/'\n",
    "    FILE_NAME = 'LDOS'\n",
    "    PARAMS = [(16, 16, 1), (32, 16, 4), (64, 32, 8), (128, 16, 16), (50, 2, 2)]\n",
    "\n",
    "# other relavant parameters\n",
    "with open(PATH+FILE_NAME+'_params.txt') as f:\n",
    "    f.readline()\n",
    "    BOXLENGTH, DATA_SIZE, NEV = list(map(int, f.readline().split(','))) \n",
    "NAMES = ['evs', 'landScapePotential', 'originalPotentialPotential']\n",
    "\n",
    "print(\"Regime:\", BOXLENGTH, DATA_SIZE, NEV)\n",
    "#EPSILON = np.finfo(np.float32).tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loading training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(names=NAMES, path=PATH, file_name=FILE_NAME):        \n",
    "    train, test= [], []\n",
    "    for i in range(len(names)):\n",
    "        train.append(loadtxt(path + file_name + '_train_' + names[i] + '.cvs', delimiter=',').astype(np.float32))\n",
    "        test.append(loadtxt(path + file_name + '_test_' + names[i] + '.cvs', delimiter=',').astype(np.float32))\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# form data for training/testing\n",
    "# NOTE: cannot set data_size=DATA_SIZE as DATA_SIZE = 0 before loading\n",
    "def form_data(train, test, data_size=DATA_SIZE, batch_size=BATCH_SIZE): \n",
    "    train_ds, test_ds = [], []\n",
    "    for i in range(len(train)-1):\n",
    "        train[i+1] = train[i+1][..., np.newaxis]\n",
    "        test[i+1] = test[i+1][..., np.newaxis]\n",
    "        train_ds.append(tf.data.Dataset.from_tensor_slices((train[i+1], train[0])).shuffle(data_size).batch(batch_size))\n",
    "        test_ds.append(tf.data.Dataset.from_tensor_slices((test[i+1], test[0])).batch(batch_size))\n",
    "    \n",
    "    return train_ds, test_ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    train, test = load()\n",
    "    print('BOXLENGTH, DATA_SIZE, NEV:')\n",
    "    print(BOXLENGTH, DATA_SIZE, NEV)\n",
    "    train_ds, test_ds = form_data(train, test) \n",
    "    print(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CNN+fc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVNN(Model):\n",
    "    def __init__(self, params=PARAMS, potential_type='', nev=NEV):\n",
    "        super(EVNN, self).__init__(name='')\n",
    "        self.potential_type = potential_type\n",
    "        \n",
    "        self.convs = []\n",
    "        self.norms = []\n",
    "        self.activs = []\n",
    "        \n",
    "        for ch_size, k_size, s_size in params:\n",
    "            self.convs.append(layers.Conv1D(ch_size, \\\n",
    "                                            kernel_size=k_size, \\\n",
    "                                            strides= s_size, \\\n",
    "                                            padding='same'))\n",
    "            self.norms.append(layers.BatchNormalization())\n",
    "            self.activs.append(layers.ReLU())\n",
    "\n",
    "        self.fc1 = layers.Dense(8*nev, activation='softplus')\n",
    "        self.fc2 = layers.Dense(4*nev, activation='softplus')\n",
    "        self.fc3 = layers.Dense(nev, activation='softplus')\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        for i in range(len(self.convs)):\n",
    "            x = self.convs[i](x)\n",
    "            x = self.norms[i](x)\n",
    "            x = self.activs[i](x)\n",
    "\n",
    "        if x.shape[0] != 1:\n",
    "            x = tf.squeeze(x)\n",
    "        else:\n",
    "            x = x[0]\n",
    "    \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1 forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    evnn = EVNN()\n",
    "    print('predictions:\\n', evnn(test[1]))\n",
    "    print('target:\\n', test[0])\n",
    "    print(evnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_ds=None, test_ds=None, epochs=EPOCHS):\n",
    "    loss_object = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(x, target):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x)\n",
    "            loss = loss_object(target, predictions)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            train_loss(loss)\n",
    "            \n",
    "            \n",
    "    @tf.function\n",
    "    def test_step(x, target):\n",
    "        predictions = model(x)\n",
    "        t_loss = loss_object(target, predictions)\n",
    "\n",
    "        test_loss(t_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        test_loss.reset_states()\n",
    "\n",
    "        for train_V, train_ev in train_ds:\n",
    "            train_step(train_V, train_ev)\n",
    "\n",
    "        for test_V, test_ev in test_ds:\n",
    "            test_step(test_V, test_ev)\n",
    "\n",
    "        template = 'Epoch {}, Loss: {}, Test Loss: {}'\n",
    "        print(template.format(epoch+1,\n",
    "                            train_loss.result(),\n",
    "                            test_loss.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(train_ds, test_ds, sample, epochs=EPOCHS):\n",
    "    \n",
    "    # defining models\n",
    "    models = []\n",
    "    models.append(EVNN(potential_type='1/u based'))\n",
    "    models.append(EVNN(potential_type='V based'))\n",
    "    \n",
    "    # training\n",
    "    for i, model in enumerate(models):\n",
    "        print(\"-------------------------------------------\")\n",
    "        print(\"| Starting training for {} model\".format(model.potential_type))\n",
    "        print(\"-------------------------------------------\")\n",
    "        \n",
    "        train(model, train_ds=train_ds[i], test_ds=test_ds[i], epochs=epochs)\n",
    "        print(\"\")\n",
    "        print(model.summary())\n",
    "        print(\"\")\n",
    "    print(\"Training finished\\n\")\n",
    "    \n",
    "    # displaying some numerical values\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"| Displaying numerical values for comparison\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"True eigenvalues:\")\n",
    "    print(sample[0][:2])\n",
    "    \n",
    "    \n",
    "    pred = []\n",
    "    for i in range(2):\n",
    "        pred.append(models[i].call(sample[i+1][:2]))\n",
    "        print(\"\")\n",
    "        print(\"Results from {} EVNN\".format(models[i].potential_type))\n",
    "        print(pred[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = form_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| Starting training for 1/u based model\n",
      "-------------------------------------------\n",
      "Epoch 1, Loss: 9.414291381835938, Test Loss: 4.845764636993408\n",
      "Epoch 2, Loss: 3.7335731983184814, Test Loss: 3.817972421646118\n",
      "Epoch 3, Loss: 3.5013697147369385, Test Loss: 3.8812313079833984\n",
      "Epoch 4, Loss: 3.075446128845215, Test Loss: 2.8533785343170166\n",
      "Epoch 5, Loss: 2.7608940601348877, Test Loss: 2.7695350646972656\n",
      "Epoch 6, Loss: 2.6440412998199463, Test Loss: 2.6232800483703613\n",
      "Epoch 7, Loss: 2.582465410232544, Test Loss: 2.3418853282928467\n",
      "Epoch 8, Loss: 2.458434581756592, Test Loss: 2.311397075653076\n",
      "Epoch 9, Loss: 2.3597564697265625, Test Loss: 2.2834384441375732\n",
      "Epoch 10, Loss: 2.382484197616577, Test Loss: 2.1826658248901367\n",
      "Epoch 11, Loss: 2.2454614639282227, Test Loss: 2.2739062309265137\n",
      "Epoch 12, Loss: 2.187278985977173, Test Loss: 2.2856719493865967\n",
      "Epoch 13, Loss: 2.1497530937194824, Test Loss: 2.2401695251464844\n",
      "Epoch 14, Loss: 2.124884843826294, Test Loss: 2.3996050357818604\n",
      "Epoch 15, Loss: 2.105985403060913, Test Loss: 2.780487298965454\n",
      "Epoch 16, Loss: 2.0621848106384277, Test Loss: 2.1143665313720703\n",
      "Epoch 17, Loss: 2.045208692550659, Test Loss: 2.157392978668213\n",
      "Epoch 18, Loss: 1.9916532039642334, Test Loss: 2.1608340740203857\n",
      "Epoch 19, Loss: 1.9745194911956787, Test Loss: 2.0603456497192383\n",
      "Epoch 20, Loss: 1.925534725189209, Test Loss: 2.1066298484802246\n",
      "Epoch 21, Loss: 1.88144850730896, Test Loss: 2.526838541030884\n",
      "Epoch 22, Loss: 1.8960464000701904, Test Loss: 2.449680805206299\n",
      "Epoch 23, Loss: 1.8119643926620483, Test Loss: 2.1984198093414307\n",
      "Epoch 24, Loss: 1.8096048831939697, Test Loss: 2.0427780151367188\n",
      "Epoch 25, Loss: 1.8087637424468994, Test Loss: 2.1164615154266357\n",
      "Epoch 26, Loss: 1.7676738500595093, Test Loss: 2.2492198944091797\n",
      "Epoch 27, Loss: 1.8089179992675781, Test Loss: 2.084444284439087\n",
      "Epoch 28, Loss: 1.7514135837554932, Test Loss: 2.094560146331787\n",
      "Epoch 29, Loss: 1.7426987886428833, Test Loss: 2.17167329788208\n",
      "Epoch 30, Loss: 1.734441876411438, Test Loss: 1.9961134195327759\n",
      "\n",
      "Model: \"evnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              multiple                  272       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            multiple                  8224      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            multiple                  65600     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            multiple                  131200    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            multiple                  12850     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch multiple                  512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch multiple                  200       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  8160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  12880     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1620      \n",
      "=================================================================\n",
      "Total params: 241,966\n",
      "Trainable params: 241,386\n",
      "Non-trainable params: 580\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "-------------------------------------------\n",
      "| Starting training for V based model\n",
      "-------------------------------------------\n",
      "Epoch 1, Loss: 13.307598114013672, Test Loss: 9.261996269226074\n",
      "Epoch 2, Loss: 8.897676467895508, Test Loss: 9.54811954498291\n",
      "Epoch 3, Loss: 10.466315269470215, Test Loss: 9.130051612854004\n",
      "Epoch 4, Loss: 9.047591209411621, Test Loss: 9.587625503540039\n",
      "Epoch 5, Loss: 9.033062934875488, Test Loss: 9.166460990905762\n",
      "Epoch 6, Loss: 8.62647533416748, Test Loss: 8.357603073120117\n",
      "Epoch 7, Loss: 8.070684432983398, Test Loss: 8.073338508605957\n",
      "Epoch 8, Loss: 7.804281234741211, Test Loss: 8.124682426452637\n",
      "Epoch 9, Loss: 7.547841548919678, Test Loss: 7.454683780670166\n",
      "Epoch 10, Loss: 7.59218692779541, Test Loss: 7.792369842529297\n",
      "Epoch 11, Loss: 7.759511947631836, Test Loss: 7.760401725769043\n",
      "Epoch 12, Loss: 7.203003406524658, Test Loss: 7.384505271911621\n",
      "Epoch 13, Loss: 8.311756134033203, Test Loss: 9.710166931152344\n",
      "Epoch 14, Loss: 8.9043550491333, Test Loss: 8.955860137939453\n",
      "Epoch 15, Loss: 8.934083938598633, Test Loss: 9.035737037658691\n",
      "Epoch 16, Loss: 8.782135963439941, Test Loss: 9.153696060180664\n",
      "Epoch 17, Loss: 9.342936515808105, Test Loss: 9.136512756347656\n",
      "Epoch 18, Loss: 9.505681991577148, Test Loss: 9.04565715789795\n",
      "Epoch 19, Loss: 8.74744987487793, Test Loss: 9.062543869018555\n",
      "Epoch 20, Loss: 8.67678451538086, Test Loss: 9.205065727233887\n",
      "Epoch 21, Loss: 9.820221900939941, Test Loss: 9.08663558959961\n",
      "Epoch 22, Loss: 8.778890609741211, Test Loss: 9.08137035369873\n",
      "Epoch 23, Loss: 8.718503952026367, Test Loss: 13.461649894714355\n",
      "Epoch 24, Loss: 7.916268348693848, Test Loss: 13.026995658874512\n",
      "Epoch 25, Loss: 6.4607954025268555, Test Loss: 11.720833778381348\n",
      "Epoch 26, Loss: 6.0345306396484375, Test Loss: 11.43730354309082\n",
      "Epoch 27, Loss: 5.720982551574707, Test Loss: 10.604963302612305\n",
      "Epoch 28, Loss: 5.659346103668213, Test Loss: 11.04409408569336\n",
      "Epoch 29, Loss: 5.566561222076416, Test Loss: 11.308802604675293\n",
      "Epoch 30, Loss: 5.5375261306762695, Test Loss: 11.413302421569824\n",
      "\n",
      "Model: \"evnn_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            multiple                  272       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            multiple                  8224      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            multiple                  65600     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            multiple                  131200    \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            multiple                  12850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch multiple                  64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch multiple                  128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch multiple                  256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch multiple                  512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch multiple                  200       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  8160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  12880     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  1620      \n",
      "=================================================================\n",
      "Total params: 241,966\n",
      "Trainable params: 241,386\n",
      "Non-trainable params: 580\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Training finished\n",
      "\n",
      "-------------------------------------------\n",
      "| Displaying numerical values for comparison\n",
      "-------------------------------------------\n",
      "True eigenvalues:\n",
      "[[0.19795957 0.22519806 0.2288175  0.25573817 0.28260174 0.2831805\n",
      "  0.3016688  0.30549544 0.3060308  0.30624765 0.3139565  0.31608215\n",
      "  0.32407776 0.32613158 0.3276882  0.32828426 0.34967276 0.35036469\n",
      "  0.35176817 0.3553222 ]\n",
      " [0.1914039  0.22958799 0.26133814 0.28241462 0.2888751  0.2948982\n",
      "  0.2969115  0.2976805  0.29883555 0.3088678  0.31016415 0.31533924\n",
      "  0.3169181  0.32267174 0.32669863 0.3311006  0.33689392 0.33824283\n",
      "  0.33942524 0.3519189 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results from 1/u based EVNN\n",
      "tf.Tensor(\n",
      "[[0.20985024 0.23257531 0.24849793 0.25749785 0.27107975 0.27908605\n",
      "  0.2892546  0.29579666 0.3003228  0.30717868 0.3188041  0.32259545\n",
      "  0.3280061  0.33256158 0.342319   0.3445739  0.34874228 0.35417396\n",
      "  0.35804123 0.361692  ]\n",
      " [0.19047536 0.24720049 0.2576425  0.26572815 0.27634412 0.28443843\n",
      "  0.29225543 0.29878297 0.30138314 0.30693427 0.31645066 0.31990537\n",
      "  0.32519236 0.32859063 0.33734837 0.3388741  0.3428651  0.34935686\n",
      "  0.35164806 0.35742787]], shape=(2, 20), dtype=float32)\n",
      "\n",
      "Results from V based EVNN\n",
      "tf.Tensor(\n",
      "[[0.07011685 0.24019955 0.25783816 0.27689502 0.2848264  0.2926939\n",
      "  0.30517343 0.30428216 0.3128532  0.3197788  0.32612732 0.3279738\n",
      "  0.336757   0.33588213 0.3473891  0.34904757 0.35049304 0.3580268\n",
      "  0.3644474  0.36768448]\n",
      " [0.22300926 0.2506352  0.26219955 0.28325158 0.28794807 0.29312003\n",
      "  0.30692875 0.3054821  0.31058353 0.31727552 0.3242386  0.32868314\n",
      "  0.33644232 0.33450246 0.3420856  0.34470016 0.35084116 0.35496545\n",
      "  0.36021844 0.36512715]], shape=(2, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "compare_models(train_ds, test_ds, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
